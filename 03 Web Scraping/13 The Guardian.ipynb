{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/uk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverpage = r1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(coverpage, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverpage_news = soup1.find_all('h3', class_='fc-item__title')\n",
    "len(coverpage_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"fc-item__title\"><a class=\"fc-item__link\" data-link-name=\"article\" href=\"https://www.theguardian.com/world/2020/apr/24/revealed-dominic-cummings-on-secret-scientific-advisory-group-for-covid-19\"><span class=\"fc-item__kicker\">Exclusive</span> <span class=\"u-faux-block-link__cta fc-item__headline\"> <span class=\"js-headline-text\">Cummings is on secret scientific advisory group for Covid-19</span></span> </a></h3>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverpage_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = len(coverpage_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 skipped\n",
      "3 skipped\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 skipped\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 skipped\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 skipped\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "50 done\n",
      "51 done\n",
      "52 done\n",
      "53 done\n",
      "54 done\n",
      "55 done\n",
      "56 done\n",
      "57 done\n",
      "58 skipped\n",
      "59 skipped\n",
      "60 skipped\n",
      "61 skipped\n",
      "62 skipped\n",
      "63 skipped\n",
      "64 skipped\n",
      "65 skipped\n",
      "66 skipped\n",
      "67 skipped\n",
      "68 done\n",
      "69 done\n",
      "70 done\n",
      "71 done\n",
      "72 done\n",
      "73 done\n",
      "74 done\n",
      "75 done\n",
      "76 done\n",
      "77 done\n",
      "78 done\n",
      "79 done\n",
      "80 done\n",
      "81 done\n",
      "82 done\n",
      "83 done\n",
      "84 done\n",
      "85 done\n",
      "86 done\n",
      "87 skipped\n",
      "88 done\n",
      "89 done\n",
      "90 done\n",
      "91 done\n",
      "92 skipped\n",
      "93 done\n",
      "94 done\n",
      "95 done\n",
      "96 done\n",
      "97 done\n",
      "98 done\n",
      "99 done\n",
      "100 done\n",
      "101 done\n",
      "102 done\n",
      "103 done\n",
      "104 done\n",
      "105 skipped\n",
      "106 skipped\n",
      "107 done\n",
      "108 skipped\n",
      "109 skipped\n",
      "110 done\n",
      "111 done\n",
      "112 done\n",
      "113 skipped\n",
      "114 done\n",
      "115 done\n",
      "116 done\n",
      "117 done\n",
      "118 done\n",
      "119 done\n",
      "120 done\n",
      "time taken: 40.02396488189697\n"
     ]
    }
   ],
   "source": [
    "# Empty lists for content, links and titles\n",
    "before = time.time()\n",
    "session = requests.session()\n",
    "news_contents = []\n",
    "list_links = []\n",
    "list_titles = []\n",
    "for n in np.arange(0, number_of_articles):\n",
    "    #Skiiping links which donot contain an article\n",
    "    if (\"live\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"ng-interactive\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"audio\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"video\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"gallery\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"picture\" in coverpage_news[n].find(\"a\")[\"href\"]):\n",
    "        print(n, \"skipped\")\n",
    "        continue\n",
    "    #time.sleep(0.5)\n",
    "    #Getting link of article\n",
    "    #time.sleep(0)\n",
    "    link = coverpage_news[n].find(\"a\")[\"href\"]\n",
    "\n",
    "    #Getting title of Article\n",
    "    title = coverpage_news[n].find(\"a\").get_text()\n",
    "    \n",
    "    #Reading the content\n",
    "    #t1 = time.time()\n",
    "    article = session.get(link)\n",
    "    #response_delay = time.time() - t1\n",
    "    #time.sleep(max(5*response_delay, 2))\n",
    "    \n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, \"html5lib\")\n",
    "    body = soup_article.find(\"div\", class_ = \"content__article-body from-content-api js-article__body\")\n",
    "    #To handle being blocked by server\n",
    "    try:\n",
    "        final_article = \" \".join([p.get_text() for p in body.find_all(\"p\")])\n",
    "        list_links.append(link)\n",
    "        list_titles.append(title)\n",
    "        news_contents.append(final_article)\n",
    "        print(n, \"done\")\n",
    "    except:\n",
    "        print(n, \"failed\")\n",
    "print(\"time taken: {}\".format(time.time()-before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.DataFrame({\"title\" : list_titles, \"link\" : list_links,\"Content\" : final_article, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting it all together in a function\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def scrap_Guardian():\n",
    "    url = \"https://www.theguardian.com/uk\"\n",
    "\n",
    "    r1 = requests.get(url)\n",
    "\n",
    "\n",
    "    coverpage = r1.content\n",
    "\n",
    "    soup1 = BeautifulSoup(coverpage, \"html5lib\")\n",
    "    coverpage_news = soup1.find_all('h3', class_='fc-item__title')\n",
    "    number_of_articles = len(coverpage_news)\n",
    "    # Empty lists for content, links and titles\n",
    "    before = time.time()\n",
    "    session = requests.session()\n",
    "    news_contents = []\n",
    "    list_links = []\n",
    "    list_titles = []\n",
    "    for n in np.arange(0, number_of_articles):\n",
    "\n",
    "        if (\"live\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"ng-interactive\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"audio\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"video\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"gallery\" in coverpage_news[n].find(\"a\")[\"href\"]) or (\"picture\" in coverpage_news[n].find(\"a\")[\"href\"]):\n",
    "            print(n, \"skipped\")\n",
    "            continue\n",
    "        #Remove this to be polite to the website\n",
    "        #time.sleep(0.25)\n",
    "        #Getting link of article\n",
    "        #time.sleep(0)\n",
    "        link = coverpage_news[n].find(\"a\")[\"href\"]\n",
    "\n",
    "        #Getting title of Article\n",
    "        title = coverpage_news[n].find(\"a\").get_text()\n",
    "\n",
    "        #Reading the content\n",
    "        #t1 = time.time()\n",
    "        article = session.get(link)\n",
    "        #response_delay = time.time() - t1\n",
    "        #time.sleep(max(5*response_delay, 2))\n",
    "\n",
    "        article_content = article.content\n",
    "        soup_article = BeautifulSoup(article_content, \"html5lib\")\n",
    "        body = soup_article.find(\"div\", class_ = \"content__article-body from-content-api js-article__body\")\n",
    "        #To handle being blocked by server\n",
    "        try:\n",
    "            final_article = \" \".join([p.get_text() for p in body.find_all(\"p\")])\n",
    "            list_links.append(link)\n",
    "            list_titles.append(title)\n",
    "            news_contents.append(final_article)\n",
    "            print(n, \"done\")\n",
    "            time.sleep(0.25)\n",
    "        except:\n",
    "            print(n, \"failed\")\n",
    "    print(\"time taken: {}\".format(time.time()-before))\n",
    "    df_articles = pd.DataFrame({\"title\" : list_titles, \"link\" : list_links,\"Content\" : final_article, })\n",
    "    return df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 skipped\n",
      "3 skipped\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 skipped\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 skipped\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 skipped\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "50 done\n",
      "51 done\n",
      "52 done\n",
      "53 done\n",
      "54 done\n",
      "55 done\n",
      "56 done\n",
      "57 done\n",
      "58 skipped\n",
      "59 skipped\n",
      "60 skipped\n",
      "61 skipped\n",
      "62 skipped\n",
      "63 skipped\n",
      "64 skipped\n",
      "65 skipped\n",
      "66 skipped\n",
      "67 skipped\n",
      "68 done\n",
      "69 done\n",
      "70 done\n",
      "71 done\n",
      "72 done\n",
      "73 done\n",
      "74 done\n",
      "75 done\n",
      "76 done\n",
      "77 done\n",
      "78 done\n",
      "79 done\n",
      "80 done\n",
      "81 done\n",
      "82 done\n",
      "83 done\n",
      "84 done\n",
      "85 done\n",
      "86 done\n",
      "87 skipped\n",
      "88 done\n",
      "89 done\n",
      "90 done\n",
      "91 done\n",
      "92 skipped\n",
      "93 done\n",
      "94 done\n",
      "95 done\n",
      "96 done\n",
      "97 done\n",
      "98 done\n",
      "99 done\n",
      "100 done\n",
      "101 done\n",
      "102 done\n",
      "103 done\n",
      "104 done\n",
      "105 skipped\n",
      "106 skipped\n",
      "107 done\n",
      "108 skipped\n",
      "109 skipped\n",
      "110 done\n",
      "111 done\n",
      "112 done\n",
      "113 skipped\n",
      "114 done\n",
      "115 done\n",
      "116 done\n",
      "117 done\n",
      "118 done\n",
      "119 done\n",
      "120 done\n",
      "time taken: 57.817381381988525\n"
     ]
    }
   ],
   "source": [
    "df = scrap_Guardian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exclusive  Cummings is on secret scientific ad...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exclusive  Cummings is on secret scientific ad...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump  Revealed: Trump hailed bleach 'c...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump  Revealed: Trump hailed bleach 'c...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armed forces  British soldiers to get insect r...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Was Trump being 'sarcastic' with his disinfe...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>British soldiers to get insect repellant as ...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Revealed: UK ministers were warned last year...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Coronavirus detected on particles of air pol...</td>\n",
       "      <td>https://www.theguardian.com/environment/2020/a...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sweden queries basis of lockdowns as Germany...</td>\n",
       "      <td>https://www.theguardian.com/world/2020/apr/24/...</td>\n",
       "      <td>Sweden questioned the scientific basis of othe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Exclusive  Cummings is on secret scientific ad...   \n",
       "1   Exclusive  Cummings is on secret scientific ad...   \n",
       "2   Donald Trump  Revealed: Trump hailed bleach 'c...   \n",
       "3   Donald Trump  Revealed: Trump hailed bleach 'c...   \n",
       "4   Armed forces  British soldiers to get insect r...   \n",
       "..                                                ...   \n",
       "94    Was Trump being 'sarcastic' with his disinfe...   \n",
       "95    British soldiers to get insect repellant as ...   \n",
       "96    Revealed: UK ministers were warned last year...   \n",
       "97    Coronavirus detected on particles of air pol...   \n",
       "98    Sweden queries basis of lockdowns as Germany...   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://www.theguardian.com/world/2020/apr/24/...   \n",
       "1   https://www.theguardian.com/world/2020/apr/24/...   \n",
       "2   https://www.theguardian.com/world/2020/apr/24/...   \n",
       "3   https://www.theguardian.com/world/2020/apr/24/...   \n",
       "4   https://www.theguardian.com/world/2020/apr/24/...   \n",
       "..                                                ...   \n",
       "94  https://www.theguardian.com/world/2020/apr/24/...   \n",
       "95  https://www.theguardian.com/world/2020/apr/24/...   \n",
       "96  https://www.theguardian.com/world/2020/apr/24/...   \n",
       "97  https://www.theguardian.com/environment/2020/a...   \n",
       "98  https://www.theguardian.com/world/2020/apr/24/...   \n",
       "\n",
       "                                              Content  \n",
       "0   Sweden questioned the scientific basis of othe...  \n",
       "1   Sweden questioned the scientific basis of othe...  \n",
       "2   Sweden questioned the scientific basis of othe...  \n",
       "3   Sweden questioned the scientific basis of othe...  \n",
       "4   Sweden questioned the scientific basis of othe...  \n",
       "..                                                ...  \n",
       "94  Sweden questioned the scientific basis of othe...  \n",
       "95  Sweden questioned the scientific basis of othe...  \n",
       "96  Sweden questioned the scientific basis of othe...  \n",
       "97  Sweden questioned the scientific basis of othe...  \n",
       "98  Sweden questioned the scientific basis of othe...  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
